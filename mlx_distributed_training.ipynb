{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX Distributed Training Notebook\n",
    "\n",
    "This notebook provides an interactive interface for running MLX distributed training using the existing modules and utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import MLX and project modules\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "from mlx_lm.tuner.trainer import TrainingCallback\n",
    "from mlx_lm.lora import run\n",
    "\n",
    "# Import custom utilities\n",
    "from utils.data_preparation import prepare_data, validate_data_format\n",
    "from utils.logging import setup_logging, get_logger\n",
    "from utils.model_cache import ModelCache\n",
    "from utils.training_callbacks import (\n",
    "    CheckpointCallback,\n",
    "    MetricsCallback,\n",
    "    EarlyStoppingCallback,\n",
    "    CombinedCallback\n",
    ")\n",
    "from utils.training_core import (\n",
    "    setup_distributed,\n",
    "    all_reduce_grads,\n",
    "    DistributedTrainingCallback,\n",
    "    run_distributed_training\n",
    ")\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"MLX version: {mx.__version__ if hasattr(mx, '__version__') else 'Unknown'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    # Model settings\n",
    "    \"model\": \"mlx-community/gemma-2-2b-it-4bit\",\n",
    "    \"adapter_path\": \"models/fine-tuned\",\n",
    "    \n",
    "    # Data settings\n",
    "    \"data_path\": \"data\",\n",
    "    \"train_file\": \"train.jsonl\",\n",
    "    \"valid_file\": \"valid.jsonl\",\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\": 1,\n",
    "    \"num_epochs\": 1,\n",
    "    \"iters\": 10,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_layers\": 4,\n",
    "    \"max_seq_length\": 128,\n",
    "    \n",
    "    # LoRA parameters\n",
    "    \"lora_rank\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.0,\n",
    "    \"lora_scale\": 10.0,\n",
    "    \n",
    "    # Reporting and checkpointing\n",
    "    \"steps_per_report\": 2,\n",
    "    \"steps_per_eval\": 5,\n",
    "    \"save_every\": 5,\n",
    "    \n",
    "    # Distributed settings\n",
    "    \"distributed\": False,  # Set to True for distributed training\n",
    "    \"hostfile\": \"hostfile\"\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data files\n",
    "data_path = Path(config[\"data_path\"])\n",
    "\n",
    "# Copy example files to expected names if they don't exist\n",
    "if not (data_path / \"train.jsonl\").exists():\n",
    "    shutil.copy(data_path / \"example_train.jsonl\", data_path / \"train.jsonl\")\n",
    "    print(\"✅ Copied example_train.jsonl to train.jsonl\")\n",
    "\n",
    "if not (data_path / \"valid.jsonl\").exists():\n",
    "    shutil.copy(data_path / \"example_valid.jsonl\", data_path / \"valid.jsonl\")\n",
    "    print(\"✅ Copied example_valid.jsonl to valid.jsonl\")\n",
    "\n",
    "# Validate data format\n",
    "print(\"\\nValidating data files...\")\n",
    "train_valid = validate_data_format(str(data_path / \"train.jsonl\"))\n",
    "valid_valid = validate_data_format(str(data_path / \"valid.jsonl\"))\n",
    "\n",
    "if train_valid and valid_valid:\n",
    "    print(\"✅ Data validation passed!\")\n",
    "else:\n",
    "    print(\"❌ Data validation failed!\")\n",
    "\n",
    "# Count samples\n",
    "with open(data_path / \"train.jsonl\", 'r') as f:\n",
    "    train_count = sum(1 for _ in f)\n",
    "with open(data_path / \"valid.jsonl\", 'r') as f:\n",
    "    valid_count = sum(1 for _ in f)\n",
    "\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"- Training samples: {train_count}\")\n",
    "print(f\"- Validation samples: {valid_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "os.makedirs(\"models/fine-tuned\", exist_ok=True)\n",
    "os.makedirs(\"models/checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(\"logs/training.log\")\n",
    "logger.info(\"Starting MLX training setup\")\n",
    "\n",
    "# Initialize model cache\n",
    "model_cache = ModelCache()\n",
    "print(\"✅ Model cache initialized\")\n",
    "\n",
    "# Check if model is already cached\n",
    "if model_cache.is_cached(config[\"model\"]):\n",
    "    print(f\"✅ Model {config['model']} is already cached\")\n",
    "else:\n",
    "    print(f\"ℹ️ Model {config['model']} will be downloaded on first use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_training(config):\n",
    "    \"\"\"Run training on a single node\"\"\"\n",
    "    print(\"Starting local training...\")\n",
    "    \n",
    "    # Create training arguments\n",
    "    from types import SimpleNamespace\n",
    "    args = SimpleNamespace(\n",
    "        model=config[\"model\"],\n",
    "        train=True,\n",
    "        data=config[\"data_path\"],\n",
    "        adapter_path=config[\"adapter_path\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        iters=config[\"iters\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        max_seq_length=config[\"max_seq_length\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        steps_per_report=config[\"steps_per_report\"],\n",
    "        steps_per_eval=config[\"steps_per_eval\"],\n",
    "        save_every=config[\"save_every\"],\n",
    "        lora_parameters={\n",
    "            \"rank\": config[\"lora_rank\"],\n",
    "            \"alpha\": config[\"lora_alpha\"],\n",
    "            \"dropout\": config[\"lora_dropout\"],\n",
    "            \"scale\": config[\"lora_scale\"]\n",
    "        },\n",
    "        fine_tune_type=\"lora\",\n",
    "        val_batches=5,\n",
    "        seed=42,\n",
    "        resume_adapter_file=None,\n",
    "        test=False,\n",
    "        test_batches=100,\n",
    "        grad_checkpoint=False,\n",
    "        lr_schedule=None,\n",
    "        wandb=None,\n",
    "        optimizer=\"adam\",\n",
    "        optimizer_config={\"adam\": {}, \"adamw\": {\"weight_decay\": 0.01}}\n",
    "    )\n",
    "    \n",
    "    # Create callbacks\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        checkpoint_dir=\"models/checkpoints\",\n",
    "        save_every=config[\"save_every\"]\n",
    "    )\n",
    "    \n",
    "    metrics_callback = MetricsCallback()\n",
    "    \n",
    "    combined_callback = CombinedCallback([\n",
    "        checkpoint_callback,\n",
    "        metrics_callback\n",
    "    ])\n",
    "    \n",
    "    # Run training\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        run(args, training_callback=combined_callback)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\n✅ Training completed in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Print final metrics\n",
    "        if metrics_callback.train_losses:\n",
    "            print(f\"Final training loss: {metrics_callback.train_losses[-1][1]:.4f}\")\n",
    "        if metrics_callback.val_losses:\n",
    "            print(f\"Final validation loss: {metrics_callback.val_losses[-1][1]:.4f}\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed with error: {e}\")\n",
    "        logger.error(f\"Training failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def run_distributed_training_notebook(config):\n",
    "    \"\"\"Run distributed training across multiple nodes\"\"\"\n",
    "    print(\"Starting distributed training...\")\n",
    "    \n",
    "    # Check if hostfile exists\n",
    "    if not os.path.exists(config[\"hostfile\"]):\n",
    "        print(f\"❌ Hostfile not found: {config['hostfile']}\")\n",
    "        return False\n",
    "    \n",
    "    # Run the distributed training script\n",
    "    cmd = \"./run_distributed_fine_tune_fixed.sh\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"Errors:\", result.stderr)\n",
    "        return result.returncode == 0\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to run distributed training: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "print(\"✅ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose training mode\n",
    "if config[\"distributed\"]:\n",
    "    print(\"🚀 Running distributed training...\")\n",
    "    success = run_distributed_training_notebook(config)\n",
    "else:\n",
    "    print(\"🚀 Running local training...\")\n",
    "    success = run_local_training(config)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✅ Training completed successfully!\")\n",
    "else:\n",
    "    print(\"\\n❌ Training failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "if success and os.path.exists(\"models/fine-tuned/adapters.safetensors\"):\n",
    "    print(\"Loading fine-tuned model for testing...\")\n",
    "    \n",
    "    try:\n",
    "        # Load model with adapters\n",
    "        model, tokenizer = load(\n",
    "            config[\"model\"],\n",
    "            adapter_path=config[\"adapter_path\"]\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Model loaded successfully!\")\n",
    "        \n",
    "        # Test prompts\n",
    "        test_prompts = [\n",
    "            \"turn on the living room lights\",\n",
    "            \"what's the temperature in the bedroom\",\n",
    "            \"play music in the kitchen\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nTesting model with sample prompts:\\n\")\n",
    "        \n",
    "        for prompt in test_prompts:\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            \n",
    "            response = generate(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                prompt=prompt,\n",
    "                max_tokens=100,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            print(f\"Response: {response}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to test model: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No fine-tuned model found to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Information and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model information\n",
    "adapter_path = Path(config[\"adapter_path\"])\n",
    "\n",
    "if adapter_path.exists():\n",
    "    print(\"📊 Model Information:\\n\")\n",
    "    \n",
    "    # List adapter files\n",
    "    adapter_files = list(adapter_path.glob(\"*.safetensors\"))\n",
    "    print(f\"Adapter files ({len(adapter_files)}):\")\n",
    "    for file in adapter_files:\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {file.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Load and display adapter config\n",
    "    config_file = adapter_path / \"adapter_config.json\"\n",
    "    if config_file.exists():\n",
    "        with open(config_file, 'r') as f:\n",
    "            adapter_config = json.load(f)\n",
    "        print(\"\\nAdapter Configuration:\")\n",
    "        print(json.dumps(adapter_config, indent=2))\n",
    "    \n",
    "    # Display training logs if available\n",
    "    log_file = Path(\"logs/training.log\")\n",
    "    if log_file.exists():\n",
    "        print(\"\\n📝 Recent training logs:\")\n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # Show last 10 lines\n",
    "            for line in lines[-10:]:\n",
    "                print(line.strip())\n",
    "else:\n",
    "    print(\"⚠️ No model files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up temporary files\n",
    "# Uncomment the following lines if you want to clean up\n",
    "\n",
    "# # Remove copied data files\n",
    "# if (data_path / \"train.jsonl\").exists():\n",
    "#     os.remove(data_path / \"train.jsonl\")\n",
    "#     print(\"Removed train.jsonl\")\n",
    "    \n",
    "# if (data_path / \"valid.jsonl\").exists():\n",
    "#     os.remove(data_path / \"valid.jsonl\")\n",
    "#     print(\"Removed valid.jsonl\")\n",
    "\n",
    "print(\"\\n✅ Notebook execution complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
